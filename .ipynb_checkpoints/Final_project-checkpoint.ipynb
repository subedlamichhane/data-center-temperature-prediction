{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras.layers as layer\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from math import floor, ceil\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=np.random.normal(loc=0.0001, scale=0.000009, size=(5000,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.34131436e-05 8.48581124e-05 9.84487969e-05 ... 1.15597336e-04\n",
      "  1.11633073e-04 7.38581308e-05]\n",
      " [8.81196671e-05 1.02539801e-04 9.84688752e-05 ... 9.26695044e-05\n",
      "  9.93790916e-05 1.01457835e-04]\n",
      " [1.08076572e-04 1.04831109e-04 8.64889477e-05 ... 1.00418239e-04\n",
      "  7.74561789e-05 1.05580196e-04]\n",
      " ...\n",
      " [8.87858049e-05 1.09871068e-04 8.90274948e-05 ... 1.11458710e-04\n",
      "  9.65913027e-05 9.53649885e-05]\n",
      " [1.07881123e-04 9.54488588e-05 1.01686747e-04 ... 9.36776557e-05\n",
      "  1.06924572e-04 9.46778570e-05]\n",
      " [1.00223414e-04 9.69509613e-05 1.10049527e-04 ... 9.71624347e-05\n",
      "  9.05227863e-05 8.57936191e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsup=np.random.uniform(low=55, high=75, size=(5000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55.68873256]\n",
      " [65.0531031 ]\n",
      " [57.18403196]\n",
      " ...\n",
      " [61.98015575]\n",
      " [60.63370705]\n",
      " [67.28798172]]\n"
     ]
    }
   ],
   "source": [
    "print(Tsup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=np.random.uniform(low=7, high=20, size=(5000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.37972227]\n",
      " [14.00184871]\n",
      " [13.93211684]\n",
      " ...\n",
      " [15.49277136]\n",
      " [ 8.88382751]\n",
      " [18.90118908]]\n"
     ]
    }
   ],
   "source": [
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "addd=np.matmul(H,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.79209161]\n",
      " [6.78333633]\n",
      " [6.79548506]\n",
      " ...\n",
      " [6.77877995]\n",
      " [6.7839543 ]\n",
      " [6.7932139 ]]\n"
     ]
    }
   ],
   "source": [
    "print(addd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=np.random.normal(loc=3, scale=2, size=(5000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.57856324]\n",
      " [3.93798907]\n",
      " [2.43909425]\n",
      " ...\n",
      " [0.44501721]\n",
      " [2.91963537]\n",
      " [4.89837009]]\n"
     ]
    }
   ],
   "source": [
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tin_true=Tsup+addd+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64.05938741]\n",
      " [75.77442851]\n",
      " [66.41861127]\n",
      " ...\n",
      " [69.20395291]\n",
      " [70.33729672]\n",
      " [78.97956571]]\n"
     ]
    }
   ],
   "source": [
    "print(Tin_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range of Tin is:  [59.1116364] to [89.53830597]\n"
     ]
    }
   ],
   "source": [
    "print(\"range of Tin is: \",min(Tin_true), \"to\", max(Tin_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Tin_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " range of Tin is:  [59.1116364]   to   [89.53830597]\n"
     ]
    }
   ],
   "source": [
    "print(\" range of Tin is: \", min(Tin_true) ,\"  to  \", max(Tin_true) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=P\n",
    "y=Tin_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.10,shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4050, 1)\n",
      "(450, 1)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN\n",
    "ann=tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='relu',input_shape=[1])) \n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
    "#ann.add(tf.keras.layers.Dense(units=512, activation='tanh'))\n",
    "#ann.add(tf.keras.layers.Dense(units=256, activation='tanh'))\n",
    "#ann.add(tf.keras.layers.Dense(units=128, activation='tanh'))\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_111 (Dense)            (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 33,409\n",
      "Trainable params: 33,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer=keras.optimizers.Adam(learning_rate=0.0001) #best=0.001\n",
    "ann.compile(optimizer = optimizer, loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = './weights/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validate=(X_val,y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/127 [============================>.] - ETA: 0s - loss: 5.2172 - mean_absolute_error: 5.2172\n",
      "Epoch 00001: val_loss improved from inf to 4.93990, saving model to ./weights\\Weights-001--4.93990.hdf5\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2180 - mean_absolute_error: 5.2180 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 2/100\n",
      "115/127 [==========================>...] - ETA: 0s - loss: 5.2075 - mean_absolute_error: 5.2075\n",
      "Epoch 00002: val_loss improved from 4.93990 to 4.93990, saving model to ./weights\\Weights-002--4.93990.hdf5\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 3/100\n",
      "112/127 [=========================>....] - ETA: 0s - loss: 5.2305 - mean_absolute_error: 5.2305\n",
      "Epoch 00003: val_loss improved from 4.93990 to 4.93990, saving model to ./weights\\Weights-003--4.93990.hdf5\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 4/100\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 5.2269 - mean_absolute_error: 5.2269\n",
      "Epoch 00004: val_loss did not improve from 4.93990\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2170 - mean_absolute_error: 5.2170 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 5/100\n",
      "115/127 [==========================>...] - ETA: 0s - loss: 5.2119 - mean_absolute_error: 5.2119\n",
      "Epoch 00005: val_loss improved from 4.93990 to 4.93989, saving model to ./weights\\Weights-005--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 6/100\n",
      "113/127 [=========================>....] - ETA: 0s - loss: 5.2263 - mean_absolute_error: 5.2263\n",
      "Epoch 00006: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 7/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.1989 - mean_absolute_error: 5.1989\n",
      "Epoch 00007: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-007--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 8/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.2061 - mean_absolute_error: 5.2061\n",
      "Epoch 00008: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 9/100\n",
      "112/127 [=========================>....] - ETA: 0s - loss: 5.2171 - mean_absolute_error: 5.2171\n",
      "Epoch 00009: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 10/100\n",
      "101/127 [======================>.......] - ETA: 0s - loss: 5.2624 - mean_absolute_error: 5.2624\n",
      "Epoch 00010: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2179 - mean_absolute_error: 5.2179 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 11/100\n",
      "107/127 [========================>.....] - ETA: 0s - loss: 5.2231 - mean_absolute_error: 5.2231\n",
      "Epoch 00011: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 12/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2176 - mean_absolute_error: 5.2176\n",
      "Epoch 00012: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 13/100\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 5.2265 - mean_absolute_error: 5.2265\n",
      "Epoch 00013: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-013--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2179 - mean_absolute_error: 5.2179 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 14/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2282 - mean_absolute_error: 5.2282\n",
      "Epoch 00014: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n",
      "Epoch 15/100\n",
      "113/127 [=========================>....] - ETA: 0s - loss: 5.1965 - mean_absolute_error: 5.1965\n",
      "Epoch 00015: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-015--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 16/100\n",
      "112/127 [=========================>....] - ETA: 0s - loss: 5.2176 - mean_absolute_error: 5.2176\n",
      "Epoch 00016: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 17/100\n",
      "114/127 [=========================>....] - ETA: 0s - loss: 5.1948 - mean_absolute_error: 5.1948\n",
      "Epoch 00017: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 18/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2206 - mean_absolute_error: 5.2206\n",
      "Epoch 00018: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-018--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 19/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2174 - mean_absolute_error: 5.2174\n",
      "Epoch 00019: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 20/100\n",
      "109/127 [========================>.....] - ETA: 0s - loss: 5.2128 - mean_absolute_error: 5.2128\n",
      "Epoch 00020: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 21/100\n",
      "109/127 [========================>.....] - ETA: 0s - loss: 5.2335 - mean_absolute_error: 5.2335\n",
      "Epoch 00021: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 22/100\n",
      "111/127 [=========================>....] - ETA: 0s - loss: 5.2088 - mean_absolute_error: 5.2088\n",
      "Epoch 00022: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 23/100\n",
      "101/127 [======================>.......] - ETA: 0s - loss: 5.2046 - mean_absolute_error: 5.2046\n",
      "Epoch 00023: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 24/100\n",
      "105/127 [=======================>......] - ETA: 0s - loss: 5.2168 - mean_absolute_error: 5.2168\n",
      "Epoch 00024: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2179 - mean_absolute_error: 5.2179 - val_loss: 4.9406 - val_mean_absolute_error: 4.9406\n",
      "Epoch 25/100\n",
      "125/127 [============================>.] - ETA: 0s - loss: 5.2150 - mean_absolute_error: 5.2150\n",
      "Epoch 00025: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "114/127 [=========================>....] - ETA: 0s - loss: 5.2182 - mean_absolute_error: 5.2182\n",
      "Epoch 00026: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 27/100\n",
      "100/127 [======================>.......] - ETA: 0s - loss: 5.2586 - mean_absolute_error: 5.2586\n",
      "Epoch 00027: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-027--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 28/100\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 5.2290 - mean_absolute_error: 5.2290\n",
      "Epoch 00028: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 29/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2184 - mean_absolute_error: 5.2184\n",
      "Epoch 00029: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 30/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.2364 - mean_absolute_error: 5.2364\n",
      "Epoch 00030: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 31/100\n",
      "111/127 [=========================>....] - ETA: 0s - loss: 5.2069 - mean_absolute_error: 5.2069\n",
      "Epoch 00031: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 32/100\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 5.2120 - mean_absolute_error: 5.2120\n",
      "Epoch 00032: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 33/100\n",
      "109/127 [========================>.....] - ETA: 0s - loss: 5.2220 - mean_absolute_error: 5.2220\n",
      "Epoch 00033: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 34/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2259 - mean_absolute_error: 5.2259\n",
      "Epoch 00034: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 35/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.2077 - mean_absolute_error: 5.2077\n",
      "Epoch 00035: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 36/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2197 - mean_absolute_error: 5.2197\n",
      "Epoch 00036: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 37/100\n",
      "102/127 [=======================>......] - ETA: 0s - loss: 5.2473 - mean_absolute_error: 5.2473\n",
      "Epoch 00037: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9404 - val_mean_absolute_error: 4.9404\n",
      "Epoch 38/100\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 5.2247 - mean_absolute_error: 5.2247\n",
      "Epoch 00038: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9404 - val_mean_absolute_error: 4.9404\n",
      "Epoch 39/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2181 - mean_absolute_error: 5.2181\n",
      "Epoch 00039: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 40/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2172 - mean_absolute_error: 5.2172\n",
      "Epoch 00040: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 41/100\n",
      "113/127 [=========================>....] - ETA: 0s - loss: 5.2207 - mean_absolute_error: 5.2207- ETA: 0s - loss: 5.3294 - mean_absolute_error: 5\n",
      "Epoch 00041: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.2179 - mean_absolute_error: 5.2179 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 42/100\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 5.2133 - mean_absolute_error: 5.2133\n",
      "Epoch 00042: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 43/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2218 - mean_absolute_error: 5.2218\n",
      "Epoch 00043: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-043--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 44/100\n",
      "106/127 [========================>.....] - ETA: 0s - loss: 5.2037 - mean_absolute_error: 5.2037\n",
      "Epoch 00044: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 45/100\n",
      "116/127 [==========================>...] - ETA: 0s - loss: 5.2069 - mean_absolute_error: 5.2069\n",
      "Epoch 00045: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 46/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2104 - mean_absolute_error: 5.2104\n",
      "Epoch 00046: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-046--4.93989.hdf5\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 47/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2175 - mean_absolute_error: 5.2175\n",
      "Epoch 00047: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 48/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2242 - mean_absolute_error: 5.2242\n",
      "Epoch 00048: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 49/100\n",
      "116/127 [==========================>...] - ETA: 0s - loss: 5.2134 - mean_absolute_error: 5.2134\n",
      "Epoch 00049: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 50/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2075 - mean_absolute_error: 5.2075\n",
      "Epoch 00050: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 51/100\n",
      "118/127 [==========================>...] - ETA: 0s - loss: 5.2323 - mean_absolute_error: 5.2323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00051: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n",
      "Epoch 52/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.2168 - mean_absolute_error: 5.2168\n",
      "Epoch 00052: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 53/100\n",
      "109/127 [========================>.....] - ETA: 0s - loss: 5.2218 - mean_absolute_error: 5.2218\n",
      "Epoch 00053: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 54/100\n",
      "113/127 [=========================>....] - ETA: 0s - loss: 5.2290 - mean_absolute_error: 5.2290\n",
      "Epoch 00054: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 55/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2195 - mean_absolute_error: 5.2195\n",
      "Epoch 00055: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n",
      "Epoch 56/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2485 - mean_absolute_error: 5.2485\n",
      "Epoch 00056: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 57/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2176 - mean_absolute_error: 5.2176\n",
      "Epoch 00057: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 58/100\n",
      "100/127 [======================>.......] - ETA: 0s - loss: 5.2338 - mean_absolute_error: 5.2338\n",
      "Epoch 00058: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 59/100\n",
      "102/127 [=======================>......] - ETA: 0s - loss: 5.1624 - mean_absolute_error: 5.1624\n",
      "Epoch 00059: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 60/100\n",
      " 99/127 [======================>.......] - ETA: 0s - loss: 5.2102 - mean_absolute_error: 5.2102\n",
      "Epoch 00060: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2169 - mean_absolute_error: 5.2169 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 61/100\n",
      " 98/127 [======================>.......] - ETA: 0s - loss: 5.2150 - mean_absolute_error: 5.2150\n",
      "Epoch 00061: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 62/100\n",
      " 99/127 [======================>.......] - ETA: 0s - loss: 5.2178 - mean_absolute_error: 5.2178\n",
      "Epoch 00062: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 63/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2129 - mean_absolute_error: 5.2129\n",
      "Epoch 00063: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n",
      "Epoch 64/100\n",
      "115/127 [==========================>...] - ETA: 0s - loss: 5.2215 - mean_absolute_error: 5.2215\n",
      "Epoch 00064: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 65/100\n",
      "114/127 [=========================>....] - ETA: 0s - loss: 5.1966 - mean_absolute_error: 5.1966\n",
      "Epoch 00065: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 66/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2180 - mean_absolute_error: 5.2180\n",
      "Epoch 00066: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.2170 - mean_absolute_error: 5.2170 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 67/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.1954 - mean_absolute_error: 5.1954\n",
      "Epoch 00067: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 68/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2169 - mean_absolute_error: 5.2169\n",
      "Epoch 00068: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 69/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2213 - mean_absolute_error: 5.2213\n",
      "Epoch 00069: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 70/100\n",
      "107/127 [========================>.....] - ETA: 0s - loss: 5.1736 - mean_absolute_error: 5.1736\n",
      "Epoch 00070: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2179 - mean_absolute_error: 5.2179 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 71/100\n",
      "108/127 [========================>.....] - ETA: 0s - loss: 5.2406 - mean_absolute_error: 5.2406\n",
      "Epoch 00071: val_loss improved from 4.93989 to 4.93989, saving model to ./weights\\Weights-071--4.93989.hdf5\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 72/100\n",
      "107/127 [========================>.....] - ETA: 0s - loss: 5.2252 - mean_absolute_error: 5.2252\n",
      "Epoch 00072: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 73/100\n",
      "108/127 [========================>.....] - ETA: 0s - loss: 5.1943 - mean_absolute_error: 5.1943\n",
      "Epoch 00073: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 74/100\n",
      "107/127 [========================>.....] - ETA: 0s - loss: 5.2501 - mean_absolute_error: 5.2501\n",
      "Epoch 00074: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 75/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2174 - mean_absolute_error: 5.2174\n",
      "Epoch 00075: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 76/100\n",
      "111/127 [=========================>....] - ETA: 0s - loss: 5.2355 - mean_absolute_error: 5.2355\n",
      "Epoch 00076: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/127 [========================>.....] - ETA: 0s - loss: 5.2222 - mean_absolute_error: 5.2222\n",
      "Epoch 00077: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 78/100\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 5.1944 - mean_absolute_error: 5.1944\n",
      "Epoch 00078: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 79/100\n",
      "104/127 [=======================>......] - ETA: 0s - loss: 5.2096 - mean_absolute_error: 5.2096\n",
      "Epoch 00079: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2180 - mean_absolute_error: 5.2180 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 80/100\n",
      "117/127 [==========================>...] - ETA: 0s - loss: 5.2294 - mean_absolute_error: 5.2294\n",
      "Epoch 00080: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 81/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2158 - mean_absolute_error: 5.2158\n",
      "Epoch 00081: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2184 - mean_absolute_error: 5.2184 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 82/100\n",
      "127/127 [==============================] - ETA: 0s - loss: 5.2174 - mean_absolute_error: 5.2174\n",
      "Epoch 00082: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 83/100\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 5.2184 - mean_absolute_error: 5.2184\n",
      "Epoch 00083: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2178 - mean_absolute_error: 5.2178 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n",
      "Epoch 84/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2261 - mean_absolute_error: 5.2261\n",
      "Epoch 00084: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 85/100\n",
      "121/127 [===========================>..] - ETA: 0s - loss: 5.2158 - mean_absolute_error: 5.2158\n",
      "Epoch 00085: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 5.2170 - mean_absolute_error: 5.2170 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 86/100\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 5.2286 - mean_absolute_error: 5.2286\n",
      "Epoch 00086: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9403 - val_mean_absolute_error: 4.9403\n",
      "Epoch 87/100\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 5.1905 - mean_absolute_error: 5.1905\n",
      "Epoch 00087: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 88/100\n",
      "125/127 [============================>.] - ETA: 0s - loss: 5.2243 - mean_absolute_error: 5.2243\n",
      "Epoch 00088: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 89/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2130 - mean_absolute_error: 5.2130\n",
      "Epoch 00089: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 90/100\n",
      "115/127 [==========================>...] - ETA: 0s - loss: 5.2129 - mean_absolute_error: 5.2129\n",
      "Epoch 00090: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2171 - mean_absolute_error: 5.2171 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 91/100\n",
      "125/127 [============================>.] - ETA: 0s - loss: 5.2234 - mean_absolute_error: 5.2234\n",
      "Epoch 00091: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 92/100\n",
      "118/127 [==========================>...] - ETA: 0s - loss: 5.2135 - mean_absolute_error: 5.2135\n",
      "Epoch 00092: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 5.2172 - mean_absolute_error: 5.2172 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 93/100\n",
      "123/127 [============================>.] - ETA: 0s - loss: 5.2331 - mean_absolute_error: 5.2331\n",
      "Epoch 00093: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 4ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 94/100\n",
      "119/127 [===========================>..] - ETA: 0s - loss: 5.2118 - mean_absolute_error: 5.2118\n",
      "Epoch 00094: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 95/100\n",
      "120/127 [===========================>..] - ETA: 0s - loss: 5.2264 - mean_absolute_error: 5.2264\n",
      "Epoch 00095: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9401 - val_mean_absolute_error: 4.9401\n",
      "Epoch 96/100\n",
      "122/127 [===========================>..] - ETA: 0s - loss: 5.2274 - mean_absolute_error: 5.2274\n",
      "Epoch 00096: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 5.2173 - mean_absolute_error: 5.2173 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 97/100\n",
      "115/127 [==========================>...] - ETA: 0s - loss: 5.2210 - mean_absolute_error: 5.2210\n",
      "Epoch 00097: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 5.2175 - mean_absolute_error: 5.2175 - val_loss: 4.9399 - val_mean_absolute_error: 4.9399\n",
      "Epoch 98/100\n",
      "102/127 [=======================>......] - ETA: 0s - loss: 5.2281 - mean_absolute_error: 5.2281\n",
      "Epoch 00098: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2174 - mean_absolute_error: 5.2174 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 99/100\n",
      "124/127 [============================>.] - ETA: 0s - loss: 5.2224 - mean_absolute_error: 5.2224\n",
      "Epoch 00099: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2176 - mean_absolute_error: 5.2176 - val_loss: 4.9400 - val_mean_absolute_error: 4.9400\n",
      "Epoch 100/100\n",
      "118/127 [==========================>...] - ETA: 0s - loss: 5.2125 - mean_absolute_error: 5.2125\n",
      "Epoch 00100: val_loss did not improve from 4.93989\n",
      "127/127 [==============================] - 0s 2ms/step - loss: 5.2177 - mean_absolute_error: 5.2177 - val_loss: 4.9402 - val_mean_absolute_error: 4.9402\n"
     ]
    }
   ],
   "source": [
    "history=ann.fit(x = X_train,y=y_train,batch_size=32,validation_data=data_validate, epochs = 100,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "wights_file = './weights\\Weights-076--4.93990.hdf5' # choose the best checkpoint \n",
    "ann.load_weights(wights_file) # load it\n",
    "ann.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 6.019520082408677\n",
      "Mean absolute error: 5.1984799707486795\n"
     ]
    }
   ],
   "source": [
    "y_annpred=ann.predict(X_test)\n",
    "ann_error=np.sqrt(np.mean(np.square(y_test-y_annpred)))\n",
    "print(\"rmse:\",ann_error) #\n",
    "mae = np.abs(y_test-y_annpred).mean()\n",
    "print(\"Mean absolute error:\",mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Frequency distribution of difference between true and predicted Tin ')"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx=[(i) for i in range(y_annpred.shape[0])]\n",
    "plt.figure(1)\n",
    "diff=abs(y_test-y_annpred)\n",
    "#plt.plot(xx,diff)\n",
    "plt.hist(diff)\n",
    "#plt.plot(xx,y_test[0:10,:])\n",
    "#plt.plot(xx,y_annpred[0:10,:])\n",
    "plt.ylabel('Number of data')\n",
    "plt.xlabel('Difference between Real and Predicted Tin (F)')\n",
    "plt.title('Frequency distribution of difference between true and predicted Tin ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Convergence')"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(history.history['loss'])\n",
    "train_loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "xloss=[(i) for i in range(len(train_loss))]\n",
    "plt.plot(xloss,train_loss)\n",
    "plt.plot(xloss,val_loss)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Mean absolute error')\n",
    "plt.legend(['train loss', 'validation loss'])\n",
    "plt.title('Loss Convergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1)\n",
      "rmse: 5.679910022284737\n",
      "Mean absolute error: 4.837118277128145\n",
      "Range of kWh: 59.80664261150397 kWh to 83.72616819716475 kWh\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test) \n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "error=np.sqrt(np.mean(np.square(y_test-y_pred)))  #without dayofweek 4.17803464\n",
    "print(\"rmse:\",error)\n",
    "mae = np.abs(y_test-y_pred).mean()\n",
    "print(\"Mean absolute error:\",mae)\n",
    "print(\"Range of kWh: {} kWh to {} kWh\".format(np.min(y_test),np.max(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Frequency distribution of difference between true and predicted Tin ')"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx=[(i) for i in range(y_annpred.shape[0])]\n",
    "plt.figure(1)\n",
    "diff=abs(y_test-y_annpred)\n",
    "#plt.plot(xx,diff)\n",
    "plt.hist(diff)\n",
    "#plt.plot(xx,y_test[0:10,:])\n",
    "#plt.plot(xx,y_annpred[0:10,:])\n",
    "plt.ylabel('Number of data')\n",
    "plt.xlabel('Difference between Real and Predicted Tin (F)')\n",
    "plt.title('Frequency distribution of difference between true and predicted Tin ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-723-4ff404880da4>:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train,y_train,shape(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
